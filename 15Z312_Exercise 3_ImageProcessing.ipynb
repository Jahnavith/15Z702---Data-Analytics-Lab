{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "# Image Processing on Movie Genre Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Problem Description</b>\n",
    "To perform image processing on Movie Genre dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "Import the required packages<br>\n",
    "We will be using the keras deep learning library to build a CNN model to analyze the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\users\\balaj\\appdata\\local\\programs\\python\\python36\\python.exe\n",
      "3.6.2 (v3.6.2:5fd33b5, Jul  8 2017, 04:57:36) [MSC v.1900 64 bit (AMD64)]\n",
      "sys.version_info(major=3, minor=6, micro=2, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import glob\n",
    "import csv\n",
    "import cv2\n",
    "from numpy import array, asarray, ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "Define the Batch size, the number of epochs and the training size of the model<br>\n",
    "We also give the input dimensions of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training controls\n",
    "batch_size = 25\n",
    "epochs = 1\n",
    "training_size = 0.7\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 268, 182\n",
    "\n",
    "# the data holders\n",
    "x_test = []\n",
    "x_train = []\n",
    "y_test= []\n",
    "y_train= []\n",
    "tempY = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "Open the CSV file and the image directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Movies\\\\110299.jpg',\n",
       " 'Movies\\\\110877.jpg',\n",
       " 'Movies\\\\111173.jpg',\n",
       " 'Movies\\\\112281.jpg',\n",
       " 'Movies\\\\112286.jpg',\n",
       " 'Movies\\\\112346.jpg',\n",
       " 'Movies\\\\112365.jpg',\n",
       " 'Movies\\\\112379.jpg',\n",
       " 'Movies\\\\112401.jpg',\n",
       " 'Movies\\\\112431.jpg',\n",
       " 'Movies\\\\112445.jpg',\n",
       " 'Movies\\\\112453.jpg',\n",
       " 'Movies\\\\112637.jpg',\n",
       " 'Movies\\\\112641.jpg',\n",
       " 'Movies\\\\112682.jpg',\n",
       " 'Movies\\\\112697.jpg',\n",
       " 'Movies\\\\112714.jpg',\n",
       " 'Movies\\\\112722.jpg',\n",
       " 'Movies\\\\112744.jpg',\n",
       " 'Movies\\\\112749.jpg',\n",
       " 'Movies\\\\112760.jpg',\n",
       " 'Movies\\\\112792.jpg',\n",
       " 'Movies\\\\112818.jpg',\n",
       " 'Movies\\\\112819.jpg',\n",
       " 'Movies\\\\112896.jpg',\n",
       " 'Movies\\\\113041.jpg',\n",
       " 'Movies\\\\113101.jpg',\n",
       " 'Movies\\\\113118.jpg',\n",
       " 'Movies\\\\113149.jpg',\n",
       " 'Movies\\\\113158.jpg',\n",
       " 'Movies\\\\113161.jpg',\n",
       " 'Movies\\\\113189.jpg',\n",
       " 'Movies\\\\113228.jpg',\n",
       " 'Movies\\\\113247.jpg',\n",
       " 'Movies\\\\113277.jpg',\n",
       " 'Movies\\\\113283.jpg',\n",
       " 'Movies\\\\113321.jpg',\n",
       " 'Movies\\\\113403.jpg',\n",
       " 'Movies\\\\113419.jpg',\n",
       " 'Movies\\\\113442.jpg',\n",
       " 'Movies\\\\113490.jpg',\n",
       " 'Movies\\\\113497.jpg',\n",
       " 'Movies\\\\113537.jpg',\n",
       " 'Movies\\\\113541.jpg',\n",
       " 'Movies\\\\113612.jpg',\n",
       " 'Movies\\\\113627.jpg',\n",
       " 'Movies\\\\113819.jpg',\n",
       " 'Movies\\\\113828.jpg',\n",
       " 'Movies\\\\113845.jpg',\n",
       " 'Movies\\\\113855.jpg',\n",
       " 'Movies\\\\113862.jpg',\n",
       " 'Movies\\\\113972.jpg',\n",
       " 'Movies\\\\113973.jpg',\n",
       " 'Movies\\\\113987.jpg',\n",
       " 'Movies\\\\114011.jpg',\n",
       " 'Movies\\\\114039.jpg',\n",
       " 'Movies\\\\114057.jpg',\n",
       " 'Movies\\\\114117.jpg',\n",
       " 'Movies\\\\114148.jpg',\n",
       " 'Movies\\\\114168.jpg',\n",
       " 'Movies\\\\114272.jpg',\n",
       " 'Movies\\\\114279.jpg',\n",
       " 'Movies\\\\114319.jpg',\n",
       " 'Movies\\\\114367.jpg',\n",
       " 'Movies\\\\114369.jpg',\n",
       " 'Movies\\\\114388.jpg',\n",
       " 'Movies\\\\114576.jpg',\n",
       " 'Movies\\\\114660.jpg',\n",
       " 'Movies\\\\114681.jpg',\n",
       " 'Movies\\\\114709.jpg',\n",
       " 'Movies\\\\114746.jpg',\n",
       " 'Movies\\\\114753.jpg',\n",
       " 'Movies\\\\114814.jpg',\n",
       " 'Movies\\\\114825.jpg',\n",
       " 'Movies\\\\114885.jpg',\n",
       " 'Movies\\\\114916.jpg',\n",
       " 'Movies\\\\114952.jpg',\n",
       " 'Movies\\\\115012.jpg',\n",
       " 'Movies\\\\115639.jpg',\n",
       " 'Movies\\\\115644.jpg',\n",
       " 'Movies\\\\115676.jpg',\n",
       " 'Movies\\\\115683.jpg',\n",
       " 'Movies\\\\115697.jpg',\n",
       " 'Movies\\\\115734.jpg',\n",
       " 'Movies\\\\115759.jpg',\n",
       " 'Movies\\\\115907.jpg',\n",
       " 'Movies\\\\116126.jpg',\n",
       " 'Movies\\\\116151.jpg',\n",
       " 'Movies\\\\116260.jpg',\n",
       " 'Movies\\\\116367.jpg',\n",
       " 'Movies\\\\116731.jpg',\n",
       " 'Movies\\\\116839.jpg',\n",
       " 'Movies\\\\117002.jpg',\n",
       " 'Movies\\\\118002.jpg',\n",
       " 'Movies\\\\118158.jpg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#opening the dataset\n",
    "dataset = csv.reader(open(\"csv/MovieGenre.csv\",encoding=\"utf8\",errors='replace'), delimiter=\",\")\n",
    "\n",
    "#skipping the header line\n",
    "next(dataset)\n",
    "\n",
    "#the list of image files in SampleMoviePosters folder\n",
    "flist=glob.glob('Movies/*.jpg')\n",
    "flist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "\n",
    "Divide the dataset into training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the data from the CSV file\n",
    "for imdbId, Link, Title, Score, Genre, Poster in dataset:\n",
    "    if(Score!=\"\"):\n",
    "        if(len((int(imdbId),float(Score)))==2):\n",
    "            tempY.append((int(imdbId),float(Score)))\n",
    "\n",
    "\n",
    "#setting the length of training data\n",
    "length=int(len(flist)*training_size)\n",
    "\n",
    "#extracting the data about the images that are available\n",
    "i=0\n",
    "\n",
    "for filename in flist:\n",
    "    name=int(filename.split('\\\\')[-1][:-4])\n",
    "    #print(name)\n",
    "    for z in tempY:\n",
    "        if(z[0]==name):\n",
    "            img = cv2.imread(filename)\n",
    "            if(i<length):\n",
    "                x_train.append(array(img))\n",
    "                y_train.append(z[1])\n",
    "            else:\n",
    "                x_test.append(array(img))\n",
    "                y_test.append(z[1])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5\n",
    "\n",
    "Normalize the given data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (66, 268, 182, 3)\n",
      "66 train samples\n",
      "29 test samples\n"
     ]
    }
   ],
   "source": [
    "#converting the data from lists to numpy arrays\n",
    "x_train=asarray(x_train,dtype=float)\n",
    "x_test=asarray(x_test,dtype=float)\n",
    "y_train=asarray(y_train,dtype=float)\n",
    "y_test=asarray(y_test,dtype=float)\n",
    "\n",
    "#scaling down the RGB data\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "#printing stats about the features\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6\n",
    "\n",
    "Define the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 266, 180, 128)     3584      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 266, 180, 128)     0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 266, 180, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 264, 178, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 264, 178, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 88, 59, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 88, 59, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 87, 58, 64)        16448     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 87, 58, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 43, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 43, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 42, 28, 64)        16448     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 42, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 21, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 21, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 20, 13, 64)        16448     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 20, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 10, 6, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10, 6, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 9, 5, 64)          16448     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 9, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 3, 1, 32)          8224      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 3, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 3, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1552      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 153,361\n",
      "Trainable params: 153,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#defining the model\n",
    "model = Sequential()\n",
    "#input\n",
    "model.add(Conv2D(128,data_format = 'channels_last', kernel_size=(3, 3),\n",
    "                 input_shape=(img_rows, img_cols,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "#convolutions\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(64, (2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(64, (2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32, (2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "#output\n",
    "model.add(Dense(1))\n",
    "\n",
    "#printing model summary\n",
    "print(model.summary())\n",
    "\n",
    "#compiling the model\n",
    "model.compile(optimizer='RMSprop', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7\n",
    "\n",
    "Fit and test the model\n",
    "\n",
    "Note: The fitting cannot be done on a local jupyter notebook, crashes on training. The snippet is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #training the model\n",
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_test, y_test))\n",
    "\n",
    "# #testing the model\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On training on a virtual machine, we get the following results. The accuracy was very low because of the small dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on 66 samples, validate on 29 samples\n",
    "# Epoch 1/10\n",
    "# 2018-10-16 19:37:11.706769: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
    "# 66/66 [==============================] - 19s 286ms/step - loss: 39.5773 - mean_absolute_error:6.1444 - val_loss: 38.5840 - val_mean_absolute_error: 6.1616\n",
    "# Epoch 2/10\n",
    "# 66/66 [==============================] - 18s 278ms/step - loss: 38.1432 - mean_absolute_error:5.8999 - val_loss: 41.1774 - val_mean_absolute_error: 6.3688\n",
    "# Epoch 3/10\n",
    "# 66/66 [==============================] - 18s 279ms/step - loss: 30.5684 - mean_absolute_error:5.0811 - val_loss: 39.9188 - val_mean_absolute_error: 6.2691\n",
    "# Epoch 4/10\n",
    "# 66/66 [==============================] - 18s 277ms/step - loss: 26.8137 - mean_absolute_error:4.2294 - val_loss: 41.4285 - val_mean_absolute_error: 6.3883\n",
    "# Epoch 5/10\n",
    "# 66/66 [==============================] - 18s 280ms/step - loss: 29.6750 - mean_absolute_error:5.1084 - val_loss: 31.5568 - val_mean_absolute_error: 5.5591\n",
    "# Epoch 6/10\n",
    "# 66/66 [==============================] - 18s 278ms/step - loss: 29.0625 - mean_absolute_error:4.6412 - val_loss: 37.1922 - val_mean_absolute_error: 6.0471\n",
    "# Epoch 7/10\n",
    "# 66/66 [==============================] - 18s 277ms/step - loss: 21.4115 - mean_absolute_error:3.8878 - val_loss: 29.9049 - val_mean_absolute_error: 5.4088\n",
    "# Epoch 8/10\n",
    "# 66/66 [==============================] - 18s 277ms/step - loss: 29.7955 - mean_absolute_error:4.9698 - val_loss: 33.5012 - val_mean_absolute_error: 5.7330\n",
    "# Epoch 9/10\n",
    "# 66/66 [==============================] - 18s 278ms/step - loss: 23.8302 - mean_absolute_error:4.3398 - val_loss: 24.9097 - val_mean_absolute_error: 4.9214\n",
    "# Epoch 10/10\n",
    "# 66/66 [==============================] - 18s 278ms/step - loss: 18.9994 - mean_absolute_error:3.6473 - val_loss: 30.4884 - val_mean_absolute_error: 5.4629\n",
    "# Test loss: 30.48841094970703\n",
    "# Test accuracy: 5.462912082672119"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
